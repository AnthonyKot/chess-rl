# Neural Network Model
## Configuration
input_size=10
output_size=5
hidden_layers=8
activation_functions=relu,relu
loss_function=HuberLoss
optimizer=SGD
learning_rate=0.01
## Weights
layer_0=Dense
layer_0_input_size=10
layer_0_output_size=8
layer_0_activation=relu
layer_0_weights_start
-0.4168786247752359,0.16477718512368664,0.3010894227672675,0.3145834919946557,0.9632077869555383,-0.4638354060779623,0.17240865241068612,0.6563129214845501,-0.44797765979903065,-0.10630199763877365
-0.562589817350488,0.19612276586602853,-5.937414309129818E-4,-0.16923033796688713,-0.10477854608038688,0.22593697792684098,0.21193882025469818,0.5853708779406114,-0.6729766040191711,0.16657045944914933
0.4222520121591109,0.8424781179218541,0.001817989379205799,0.5688519954729232,-0.3263568089495617,-0.2592726494343645,0.2839405883872438,0.2580463439531837,-0.22157375793831344,-0.2237204413315243
-0.17399215288145123,-0.5732302954556672,0.16689165247590987,-0.1681514229136178,0.47683619305949304,-1.0020130979524453,-0.20271321361144404,0.11424498587533147,-0.0659745090714905,0.011676185332675459
0.13156070336463382,-0.14892472359608688,-0.39760933135554244,0.3336367236775863,0.6731123480590137,-0.09531002120493058,0.9815557372807486,-0.39150731379464615,0.11051825988247395,-0.6689862161306415
-0.2805869699190305,-0.1919983094934414,-1.2010090864594185,-0.3882303072585813,0.0030258285200452585,0.49364445207328134,0.23019095667510295,-0.49506895441362897,0.056993031658433044,-0.09734288176371032
1.0285795511303528,0.09645549026438371,-0.07146018552416046,-0.8824527308716825,-0.3246318131814217,0.2344554126396548,-0.023114484462709788,-0.1874827194710541,-0.9214864491476552,-0.29070436965919433
0.20232499474482252,-0.29235305688899704,0.13534187308901516,-0.05184890012439199,0.10936155267628385,-0.7552237177440846,-0.14792555053350254,0.6078753048566492,0.11605484258863456,0.44881144572916865
layer_0_weights_end
layer_0_biases=-0.009999989184596455,0.0,-0.009999919856784379,0.0,-0.009999984698498516,0.0,0.0,0.009999839110385435
layer_1=Dense
layer_1_input_size=8
layer_1_output_size=5
layer_1_activation=relu
layer_1_weights_start
-0.639237667707811,-0.10715256834382851,-0.04081546582485045,-0.38232741627788297,-0.6419945220952051,0.2687223585190736,-0.37683244636572183,-0.19327666277453148
0.3234936121216254,-0.6097709749763452,-0.3142516105019636,-0.2166920645681222,-0.606686653450588,-0.0014753446871849315,0.9270074646017442,1.1936729472045677
-0.6900624105143234,0.06701921149773152,0.17733632499172022,-0.19516171973994723,-0.14491276004118492,0.1017142986756267,-0.29596607595758695,-0.15577814076167384
0.156706801328439,-0.8074429690321803,-0.3916233821613746,-0.4435443513576485,-0.22181116330828737,-0.11331597719306971,0.539756991318773,0.4296446824982737
-0.39118788206880434,-0.4557066987103325,-0.1557684373074963,-0.11423116383881826,-0.11416209280948315,-0.6749307535163347,-1.0216582039153084,0.18797993728179274
layer_1_weights_end
layer_1_biases=0.009999984188636698,0.009999902615070024,0.009999981027907496,0.009999937812612075,0.009999980018377382
