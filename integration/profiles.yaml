  dqn_unlock_elo_prioritized:
    # Unlock phase with prioritized replay + Elo-based best selection parameters
    hiddenLayers: 512,256,128
    enableDoubleDQN: true
    maxStepsPerGame: 60
    maxConcurrentGames: 8
    explorationRate: 0.20
    explorationWarmupCycles: 8
    explorationWarmupRate: 0.35
    opponentWarmupCycles: 8
    opponentUpdateStrategy: HISTORICAL
    opponentUpdateFrequency: 1
    opponentHistoryLag: 1
    enablePositionRewards: false
    drawReward: -0.2
    stepLimitPenalty: -1.0
    # Right-size per-step penalty; keep win/loss at Â±1
    stepPenalty: -0.002
    # Disable early: let decisive outcomes dominate reward signal
    gameLengthNormalization: false
    batchSize: 64
    targetUpdateFrequency: 20
    checkpointDirectory: checkpoints/unlock_elo_prioritized
    checkpointInterval: 2
    autoCleanupOnFinish: true
    keepBest: true
    keepLastN: 2
    treatStepLimitAsDraw: true
    replayType: PRIORITIZED
    # Anti-repetition controls
    enableLocalThreefoldDraw: true
    localThreefoldThreshold: 3
    repetitionPenalty: -0.05
    repetitionPenaltyAfter: 2
  dqn_imitation_bootstrap:
    # Warm-start DQN from an imitation checkpoint trained on chess-engine move examples
    hiddenLayers: 512,256,128
    enablePositionRewards: false
    maxStepsPerGame: 180
    maxConcurrentGames: 8
    explorationRate: 0.20
    explorationWarmupCycles: 4
    explorationWarmupRate: 0.35
    batchSize: 64
    checkpointDirectory: checkpoints/advanced
    checkpointInterval: 2
    autoCleanupOnFinish: true
    keepBest: true
    keepLastN: 2
    treatStepLimitAsDraw: true
    targetUpdateFrequency: 20
    opponentWarmupCycles: 4
    opponentUpdateStrategy: HISTORICAL
    opponentUpdateFrequency: 3
    opponentHistoryLag: 4
    enableDoubleDQN: true
    drawReward: -0.2
    stepLimitPenalty: -1.0
    # New: model path to load at start if --load not provided
    loadModelPath: ../chess-engine/data/imitation_qnet.json

  
    # Encourage decisive outcomes and avoid step-limit endings
    drawReward: -0.05
    stepLimitPenalty: -0.2
    treatStepLimitAsDraw: true
    # Training / replay
    batchSize: 64
    experienceCleanupStrategy: LOWEST_QUALITY
    # Target/updates (kept modest for stability during diagnostics)
    targetUpdateFrequency: 40
    # Checkpointing
    checkpointDirectory: checkpoints/advanced
    checkpointInterval: 2
    autoCleanupOnFinish: true
    keepBest: true
    keepLastN: 2
    # Optional algorithm toggles used elsewhere in repo
    enableDoubleDQN: true
